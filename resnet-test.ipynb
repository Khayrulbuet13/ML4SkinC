{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80731352",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-30T13:25:09.786023Z",
     "iopub.status.busy": "2024-07-30T13:25:09.785632Z",
     "iopub.status.idle": "2024-07-30T13:25:09.800903Z",
     "shell.execute_reply": "2024-07-30T13:25:09.799941Z"
    },
    "papermill": {
     "duration": 0.022208,
     "end_time": "2024-07-30T13:25:09.802892",
     "exception": false,
     "start_time": "2024-07-30T13:25:09.780684",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['resnet18_vsloss_v2']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.listdir(\"/kaggle/input/resnet18-vsloss-v2\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af9ce16b",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-07-30T13:25:09.810324Z",
     "iopub.status.busy": "2024-07-30T13:25:09.809849Z",
     "iopub.status.idle": "2024-07-30T13:25:20.686283Z",
     "shell.execute_reply": "2024-07-30T13:25:20.685507Z"
    },
    "papermill": {
     "duration": 10.882602,
     "end_time": "2024-07-30T13:25:20.688680",
     "exception": false,
     "start_time": "2024-07-30T13:25:09.806078",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from checkpoint/30 July 09:37-resnet50-VS_loss-SGD_gamma.9.pt\n",
      "Processed 500 samples\n",
      "Partial AUC: 0.1136\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import numpy as np\n",
    "import io  # Ensure io is imported for handling byte streams\n",
    "import logging, os\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "\n",
    "# Define a custom dataset class to handle HDF5 files\n",
    "class HDF5Dataset(Dataset):\n",
    "    def __init__(self, hdf5_file, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            hdf5_file (string): Path to the HDF5 file with images.\n",
    "            transform (callable, optional): Optional transform to be applied on a sample.\n",
    "        \"\"\"\n",
    "        self.hdf5_file = hdf5_file\n",
    "        self.transform = transform\n",
    "        # Open the HDF5 file\n",
    "        self.file = h5py.File(hdf5_file, 'r')\n",
    "        self.keys = list(self.file.keys())\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.keys)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # HDF5 keys can be used to access images\n",
    "        image_name = self.keys[idx]\n",
    "        image_data = self.file[image_name][()]\n",
    "        # Convert image data to PIL Image for consistency with transforms\n",
    "        image = Image.open(io.BytesIO(image_data)).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, image_name\n",
    "\n",
    "    def close(self):\n",
    "        if self.file:\n",
    "            self.file.close()\n",
    "\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, csv_file, img_dir, class_mapping, columns=None, transform=None):\n",
    "        \"\"\"\n",
    "        Initializes the dataset.\n",
    "        :param csv_file: Path to the CSV file containing data.\n",
    "        :param img_dir: Directory where images are stored.\n",
    "        :param class_mapping: Dictionary mapping class names to numeric values.\n",
    "        :param columns: List of column names to include as features. If None, all columns are included.\n",
    "        :param transform: Optional transform to be applied on a sample.\n",
    "        \"\"\"\n",
    "        self.data_frame = pd.read_csv(csv_file, low_memory=False)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        # Use specified columns if provided, otherwise use all columns starting from the third column\n",
    "        if columns is not None:\n",
    "            self.csv_data = self.data_frame[columns]\n",
    "        # Ensure the image names include the file extension if it's missing\n",
    "        self.data_frame['image_name'] = self.data_frame['isic_id'].apply(lambda x: f\"{x}.jpg\" if not x.lower().endswith('.jpg') else x)\n",
    "        # Directly use the numeric targets from the dataset\n",
    "        self.targets = self.data_frame['target'].astype(int)\n",
    "        self.class_mapping = class_mapping\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.data_frame.loc[idx, 'image_name']\n",
    "        img_path = os.path.join(self.img_dir, img_name)\n",
    "        try:\n",
    "            image = Image.open(img_path)\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "        except FileNotFoundError:\n",
    "            logging.error(f\"Image not found: {img_path}\")\n",
    "            return None  # Consider how you handle missing images in your training loop\n",
    "\n",
    "        target = self.targets[idx]\n",
    "        return image, target\n",
    "\n",
    "# Initialize device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),  # Adjust the size to 224x224 for ResNet50\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.6984, 0.5219, 0.4197], std=[0.1396, 0.1318, 0.1236]),  # Use ImageNet norms\n",
    "])\n",
    "\n",
    "# Create the dataset\n",
    "# hdf5_file = '/kaggle/input/isic-2024-challenge/test-image.hdf5'\n",
    "hdf5_file = 'dataset/dump/train-image.hdf5'\n",
    "val_csv = 'dataset/val.csv'\n",
    "val_dir = 'dataset/val'\n",
    "class_mapping = {'benign': 0, 'malignant': 1}\n",
    "columns_to_use  = None\n",
    "dataset = MyDataset(csv_file=val_csv, img_dir=val_dir, class_mapping=class_mapping, columns=columns_to_use, transform=transform)\n",
    "\n",
    "# Create the DataLoader\n",
    "test_loader = DataLoader(dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "\n",
    "# Model setup\n",
    "model = models.resnet50()\n",
    "num_ftrs = model.fc.in_features\n",
    "\n",
    "\n",
    "model.fc = nn.Linear(num_ftrs, 2)  # Assuming 2 classes (benign and malignant)\n",
    "# model = model.to(device)\n",
    "\n",
    "    \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Load existing model if available\n",
    "# model_saved_path = os.path.join(\"/kaggle/input/resnet50-gamma-9/Resnet50_gamma.9\")\n",
    "model_saved_path = os.path.join(\"checkpoint/30 July 09:37-resnet50-VS_loss-SGD_gamma.9.pt\")\n",
    "if os.path.exists(model_saved_path):\n",
    "    # Load state dict properly onto the specified device\n",
    "    model.load_state_dict(torch.load(model_saved_path, map_location=device))\n",
    "    print(f'Model loaded from {model_saved_path}')\n",
    "    logging.info(f'Model loaded from {model_saved_path}')\n",
    "else: \n",
    "    print('model not found')\n",
    "\n",
    "\n",
    "model.eval()\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "def calculate_auc(model, data_loader, device):\n",
    "    model.eval()  # Ensure the model is in evaluation mode\n",
    "    true_labels = []\n",
    "    predictions = []\n",
    "\n",
    "    count = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in data_loader:\n",
    "            inputs = inputs.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            probabilities = F.softmax(outputs, dim=1)\n",
    "            class_one_prob = probabilities[:, 1].cpu().numpy()\n",
    "            predictions.extend(class_one_prob)\n",
    "            true_labels.extend(labels)\n",
    "            count += 1\n",
    "            if count >= 500:\n",
    "                print(f'Processed {count} samples')\n",
    "                break\n",
    "\n",
    "    # Calculate pAUC using sklearn's roc_auc_score with max_fpr\n",
    "    partial_auc_scaled = roc_auc_score(true_labels, predictions, max_fpr=0.2)\n",
    "\n",
    "    # Scale from [0.5, 1.0] to [0.0, 0.2]\n",
    "    partial_auc = (partial_auc_scaled - 0.5) * 0.4\n",
    "\n",
    "    return partial_auc\n",
    "\n",
    "print(f'Partial AUC: {calculate_auc(model, test_loader, device):.4f}')\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "262e8531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 500 samples\n",
      "Partial AUC: 0.1136\n"
     ]
    }
   ],
   "source": [
    "from torchvision import transforms as T\n",
    "from data.transformation import ImgAugTransform\n",
    "# Define the test time augmentation function\n",
    "def test_time_augmentation(model, image, transforms):\n",
    "    image = image.unsqueeze(0)\n",
    "    predictions = []\n",
    "    for transform in transforms:\n",
    "        augmented_image = transform(image)\n",
    "        augmented_image = augmented_image.unsqueeze(0)  # Add batch dimension\n",
    "        augmented_image = augmented_image.to(device)\n",
    "        output = model(augmented_image)\n",
    "        predictions.append(output)\n",
    "    return torch.mean(torch.stack(predictions), dim=0)\n",
    "\n",
    "# Apply TTA during evaluation\n",
    "tta_transforms = [\n",
    "    T.Compose([T.Resize((64, 64)), T.ToTensor(), T.Normalize((0.6984, 0.5219, 0.4197), (0.1396, 0.1318, 0.1236))]),\n",
    "    T.Compose([T.Resize((64, 64)), ImgAugTransform(), T.ToTensor(), T.Normalize((0.6984, 0.5219, 0.4197), (0.1396, 0.1318, 0.1236))]),\n",
    "    T.Compose([T.Resize((64, 64)), T.RandomHorizontalFlip(p=1), T.ToTensor(), T.Normalize((0.6984, 0.5219, 0.4197), (0.1396, 0.1318, 0.1236))]),\n",
    "    T.Compose([T.Resize((64, 64)), T.RandomVerticalFlip(p=1), T.ToTensor(), T.Normalize((0.6984, 0.5219, 0.4197), (0.1396, 0.1318, 0.1236))]),\n",
    "    T.Compose([T.Resize((64, 64)), T.RandomRotation(90), T.ToTensor(), T.Normalize((0.6984, 0.5219, 0.4197), (0.1396, 0.1318, 0.1236))])\n",
    "]\n",
    "\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "def calculate_auc(model, data_loader, device):\n",
    "    model.eval()  # Ensure the model is in evaluation mode\n",
    "    true_labels = []\n",
    "    predictions = []\n",
    "\n",
    "    count = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in data_loader:\n",
    "            inputs = inputs.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            probabilities = F.softmax(outputs, dim=1)\n",
    "            class_one_prob = probabilities[:, 1].cpu().numpy()\n",
    "            predictions.extend(class_one_prob)\n",
    "            true_labels.extend(labels)\n",
    "            count += 1\n",
    "            if count >= 500:\n",
    "                print(f'Processed {count} samples')\n",
    "                break\n",
    "\n",
    "    # Calculate pAUC using sklearn's roc_auc_score with max_fpr\n",
    "    partial_auc_scaled = roc_auc_score(true_labels, predictions, max_fpr=0.2)\n",
    "\n",
    "    # Scale from [0.5, 1.0] to [0.0, 0.2]\n",
    "    partial_auc = (partial_auc_scaled - 0.5) * 0.4\n",
    "\n",
    "    return partial_auc\n",
    "\n",
    "print(f'Partial AUC: {calculate_auc(model, test_loader, device):.4f}')\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99e799be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-30T13:25:20.696812Z",
     "iopub.status.busy": "2024-07-30T13:25:20.696076Z",
     "iopub.status.idle": "2024-07-30T13:25:20.709268Z",
     "shell.execute_reply": "2024-07-30T13:25:20.708241Z"
    },
    "papermill": {
     "duration": 0.019287,
     "end_time": "2024-07-30T13:25:20.711282",
     "exception": false,
     "start_time": "2024-07-30T13:25:20.691995",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to submission.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Save predictions to CSV\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'isic_id': image_ids,\n",
    "    'target': predictions\n",
    "})\n",
    "df.to_csv('submission.csv', index=False)\n",
    "print(\"Predictions saved to submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02e87d60",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-30T13:25:20.719728Z",
     "iopub.status.busy": "2024-07-30T13:25:20.719090Z",
     "iopub.status.idle": "2024-07-30T13:25:20.745058Z",
     "shell.execute_reply": "2024-07-30T13:25:20.744203Z"
    },
    "papermill": {
     "duration": 0.032248,
     "end_time": "2024-07-30T13:25:20.747011",
     "exception": false,
     "start_time": "2024-07-30T13:25:20.714763",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isic_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ISIC_0015657</td>\n",
       "      <td>0.749103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISIC_0015729</td>\n",
       "      <td>0.014884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ISIC_0015740</td>\n",
       "      <td>0.000320</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        isic_id    target\n",
       "0  ISIC_0015657  0.749103\n",
       "1  ISIC_0015729  0.014884\n",
       "2  ISIC_0015740  0.000320"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('submission.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df74b6ae",
   "metadata": {
    "papermill": {
     "duration": 0.00314,
     "end_time": "2024-07-30T13:25:20.753616",
     "exception": false,
     "start_time": "2024-07-30T13:25:20.750476",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5094e5a",
   "metadata": {
    "papermill": {
     "duration": 0.002926,
     "end_time": "2024-07-30T13:25:20.759676",
     "exception": false,
     "start_time": "2024-07-30T13:25:20.756750",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 9094797,
     "sourceId": 63056,
     "sourceType": "competition"
    },
    {
     "datasetId": 5346498,
     "sourceId": 8886841,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5350305,
     "sourceId": 8899733,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5350915,
     "sourceId": 8900741,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5354976,
     "sourceId": 8906422,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5374694,
     "sourceId": 8933843,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5384261,
     "sourceId": 8947324,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5468614,
     "sourceId": 9067057,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5468831,
     "sourceId": 9067334,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30732,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 16.479197,
   "end_time": "2024-07-30T13:25:22.947341",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-07-30T13:25:06.468144",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
