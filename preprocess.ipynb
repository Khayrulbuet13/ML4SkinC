{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Paths for CSV and images\n",
    "csv_file_path = 'skin_cancer/dataset/train-metadata.csv'\n",
    "image_dir = 'skin_cancer/dataset/train-image/image/'\n",
    "\n",
    "# Split directories\n",
    "train_dir = 'skin_cancer/dataset/train/'\n",
    "val_dir = 'skin_cancer/dataset/val/'\n",
    "\n",
    "# Create directories if they don't exist\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "os.makedirs(val_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = 'skin_cancer/dataset/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['image_name'] = train_df['isic_id'] + '.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your dataset\n",
    "data = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Split the data into a 60% train and 40% validation set\n",
    "train_df, val_df = train_test_split(data, test_size=0.4, random_state=42)  # Random state for reproducibility\n",
    "\n",
    "# Save the new datasets to CSV files\n",
    "train_csv_path = os.path.join(base_dir, 'train.csv')\n",
    "val_csv_path = os.path.join(base_dir, 'val.csv')\n",
    "train_df.to_csv(train_csv_path, index=False)\n",
    "val_df.to_csv(val_csv_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# Function to move images\n",
    "def move_images(df, source_dir, target_dir):\n",
    "    for isic_id in df['isic_id']:  # Assuming the column name that stores image filenames\n",
    "        image_name = isic_id + '.jpg'\n",
    "        source_path = os.path.join(source_dir, image_name)\n",
    "        target_path = os.path.join(target_dir, image_name)\n",
    "        if os.path.exists(source_path):\n",
    "            shutil.copy(source_path, target_path)\n",
    "        else:\n",
    "            print(f\"Warning: {source_path} does not exist and cannot be moved.\")\n",
    "\n",
    "# Move images to their respective directories\n",
    "move_images(train_df, image_dir, train_dir)\n",
    "move_images(val_df, image_dir, val_dir)\n",
    "\n",
    "print(f\"Train dataset and images saved to {train_dir}\")\n",
    "print(f\"Validation dataset and images saved to {val_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Specify the path to your CSV file\n",
    "csv_file_path = 'dataset/dump/train-metadata.csv'\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Check the distribution of the 'target' column\n",
    "count_total = len(data['target'])\n",
    "count_zeros = (data['target'] == 0).sum()\n",
    "count_ones = (data['target'] == 1).sum()\n",
    "\n",
    "# Calculate percentages\n",
    "percentage_zeros = (count_zeros / count_total) * 100\n",
    "percentage_ones = (count_ones / count_total) * 100\n",
    "\n",
    "# Print the results\n",
    "print(f\"Percentage of 0s: {percentage_zeros:.2f}%\")\n",
    "print(f\"Percentage of 1s: {percentage_ones:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import numpy as np\n",
    "import io  # Ensure io is imported for handling byte streams\n",
    "import logging, os\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Define a custom dataset class to handle HDF5 files\n",
    "class HDF5Dataset(Dataset):\n",
    "    def __init__(self, hdf5_file, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            hdf5_file (string): Path to the HDF5 file with images.\n",
    "            transform (callable, optional): Optional transform to be applied on a sample.\n",
    "        \"\"\"\n",
    "        self.hdf5_file = hdf5_file\n",
    "        self.transform = transform\n",
    "        # Open the HDF5 file\n",
    "        self.file = h5py.File(hdf5_file, 'r')\n",
    "        self.keys = list(self.file.keys())\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.keys)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # HDF5 keys can be used to access images\n",
    "        image_name = self.keys[idx]\n",
    "        image_data = self.file[image_name][()]\n",
    "        # Convert image data to PIL Image for consistency with transforms\n",
    "        image = Image.open(io.BytesIO(image_data)).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, image_name\n",
    "\n",
    "    def close(self):\n",
    "        if self.file:\n",
    "            self.file.close()\n",
    "\n",
    "# Initialize device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),  # Adjust the size to 224x224 for ResNet50\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # Use ImageNet norms\n",
    "])\n",
    "\n",
    "# Create the dataset\n",
    "hdf5_file = 'dataset/dump/test-image.hdf5'\n",
    "dataset = HDF5Dataset(hdf5_file=hdf5_file, transform=transform)\n",
    "\n",
    "# Create the DataLoader\n",
    "test_loader = DataLoader(dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "# Model setup\n",
    "model = models.resnet101()\n",
    "num_ftrs = model.fc.in_features\n",
    "\n",
    "\n",
    "model.fc = nn.Linear(num_ftrs, 2)  # Assuming 2 classes (benign and malignant)\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "# mlp = MLP(input_size=3, hidden_size=32, output_size=16)\n",
    "# model = CombinedModel(mlp=mlp, n_classes=2, train_resnet=params['train_resnet']).to(device)\n",
    "\n",
    "\n",
    "# Load existing model if available\n",
    "model_saved_path = os.path.join(\"checkpoint/07 July 14:01-partial_auc_resnet101.pt\")\n",
    "if os.path.exists(model_saved_path):\n",
    "    model.load_state_dict(torch.load(model_saved_path))\n",
    "    logging.info(f'Model loaded from {model_saved_path}')\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# Perform inference\n",
    "predictions = []\n",
    "image_ids = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, ids in test_loader:\n",
    "        images = images.to(device)\n",
    "        outputs = model(images)\n",
    "        probabilities = F.softmax(outputs, dim=1)\n",
    "        # Extract the probability of class 1 for each image\n",
    "        class_one_prob = probabilities[:, 1].cpu().numpy()\n",
    "        predictions.extend(class_one_prob)\n",
    "        image_ids.extend(ids)\n",
    "        \n",
    "        \n",
    "# Cleanup dataset\n",
    "dataset.close()\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'isic_id': image_ids,\n",
    "    'target': predictions\n",
    "})\n",
    "df.to_csv('sample_submission.csv', index=False)\n",
    "print(\"Predictions saved to sample_submission.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skin",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
